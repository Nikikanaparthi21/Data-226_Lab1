# -*- coding: utf-8 -*-
"""New_lab_1.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EdXNhOKWpG0LTtiZhTutfd6J4B7YC8WA
"""

from airflow import DAG
from airflow.decorators import task
from airflow.models import Variable
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook

from datetime import datetime, timedelta
import yfinance as yf
import pandas as pd
import json

SNOWFLAKE_CONN_ID = "snowflake_conn"
RAW_SCHEMA        = "RAW"
TARGET_TABLE      = f"{RAW_SCHEMA}.MARKET_DATA"
STAGING_TABLE     = f"{RAW_SCHEMA}.MARKET_DATA_STG"

def _sf_cursor():
    hook = SnowflakeHook(snowflake_conn_id=SNOWFLAKE_CONN_ID)
    conn = hook.get_conn()
    try:
        conn.autocommit = False
    except Exception:
        pass
    return conn, conn.cursor()

with DAG(
    dag_id="part1_create_and_load",
    start_date=datetime(2025, 9, 29),
    schedule="10 2 * * *",  # 02:10 daily
    catchup=False,
    tags=["Lab 1"],
    default_args={"retries": 2, "retry_delay": timedelta(minutes=5)},
) as dag:

    @task()
    def ensure_tables():
        ddl = f"""
        CREATE SCHEMA IF NOT EXISTS {RAW_SCHEMA};

        CREATE TABLE IF NOT EXISTS {TARGET_TABLE} (
          SYMBOL STRING NOT NULL,
          DATE   DATE   NOT NULL,
          OPEN   FLOAT,
          HIGH   FLOAT,
          LOW    FLOAT,
          CLOSE  FLOAT,
          VOLUME NUMBER,
          CONSTRAINT PK_MARKET_DATA PRIMARY KEY (SYMBOL, DATE)
        );

        CREATE TABLE IF NOT EXISTS {STAGING_TABLE} LIKE {TARGET_TABLE};
        """
        conn, cur = _sf_cursor()
        try:
            cur.execute("BEGIN")
            for stmt in [s for s in ddl.split(";") if s.strip()]:
                cur.execute(stmt)
            cur.execute("COMMIT")
        except Exception:
            try: cur.execute("ROLLBACK")
            except Exception: pass
            raise
        finally:
            cur.close(); conn.close()

    @task()
    def fetch_prices() -> list:
        """Fetch last LOOKBACK_DAYS for each symbol via yfinance; return a flat list of row dicts."""
        lookback_days = int(Variable.get("LOOKBACK_DAYS", "180"))
        symbols = json.loads(Variable.get("SYMBOLS_JSON", '["CSCO","NVDA","MSFT","AMZN"]'))

        rows = []
        for sym in symbols:
            hist = yf.Ticker(sym).history(
                period=f"{lookback_days+10}d",
                interval="1d",
                actions=False,
                auto_adjust=False
            )
            if hist is None or hist.empty:
                continue
            hist = hist.dropna(subset=["Open","High","Low","Close","Volume"]).copy()
            hist.reset_index(inplace=True)         # Date column
            hist["Date"] = pd.to_datetime(hist["Date"]).dt.date
            hist = hist.sort_values("Date").tail(lookback_days)

            for _, r in hist.iterrows():
                rows.append({
                    "SYMBOL": sym,
                    "DATE": str(r["Date"]),         # ISO yyyy-mm-dd
                    "OPEN": float(r["Open"]),
                    "HIGH": float(r["High"]),
                    "LOW":  float(r["Low"]),
                    "CLOSE": float(r["Close"]),
                    "VOLUME": int(r["Volume"]),
                })
        return rows

    @task()
    def load_rows(rows: list):
        """Transactional load via staging + MERGE, so we upsert cleanly each day."""
        if not rows:
            return "No data to load"

        conn, cur = _sf_cursor()
        try:
            cur.execute("BEGIN")
            cur.execute(f"TRUNCATE TABLE {STAGING_TABLE}")

            ins_sql = f"""
                INSERT INTO {STAGING_TABLE}
                (SYMBOL, DATE, OPEN, HIGH, LOW, CLOSE, VOLUME)
                VALUES (%(SYMBOL)s, %(DATE)s, %(OPEN)s, %(HIGH)s, %(LOW)s, %(CLOSE)s, %(VOLUME)s)
            """
            # executemany binds dict parameters efficiently
            cur.executemany(ins_sql, rows)

            merge_sql = f"""
                MERGE INTO {TARGET_TABLE} t
                USING {STAGING_TABLE} s
                ON t.SYMBOL = s.SYMBOL AND t.DATE = s.DATE
                WHEN MATCHED THEN UPDATE SET
                    t.OPEN = s.OPEN, t.HIGH = s.HIGH, t.LOW = s.LOW, t.CLOSE = s.CLOSE, t.VOLUME = s.VOLUME
                WHEN NOT MATCHED THEN INSERT
                    (SYMBOL, DATE, OPEN, HIGH, LOW, CLOSE, VOLUME)
                VALUES
                    (s.SYMBOL, s.DATE, s.OPEN, s.HIGH, s.LOW, s.CLOSE, s.VOLUME)
            """
            cur.execute(merge_sql)
            cur.execute("COMMIT")
            return f"Loaded {len(rows)} rows into {TARGET_TABLE}"
        except Exception:
            try: cur.execute("ROLLBACK")
            except Exception: pass
            raise
        finally:
            cur.close(); conn.close()

    _ensure = ensure_tables()
    _rows   = fetch_prices()
    _load   = load_rows(_rows)
    _ensure >> _rows >> _load

